# Conversational Chat Optimizations
# Optimized for real-time conversation where queries are rarely repeated

# Embedding Cache (Increased for conversational use)
CHAT_EMBED_TTL_MS=7200000
CHAT_EMBED_CACHE_MAX=5000

# Response Cache (Reduced TTL for conversational freshness)
CHAT_RESPONSE_TTL_MS=1800000
CHAT_RESPONSE_CACHE_MAX=1000

# LLM Model (Fastest for conversational)
OPENAI_CHAT_MODEL=gpt-4o-mini

# Token Limits (Reduced for speed)
CHAT_MAX_TOKENS=1500
CHAT_MAX_SOURCES=4

# Streaming (Enabled for better UX)
CHAT_USE_STREAMING=true

# SQG Optimizations
CHAT_USE_SQG=true
CHAT_SIMPLE_QUERY_SKIP_SQG=true

# Reranking (Faster for conversational)
CHAT_RERANK_MODE=cross-encoder

# Confidence Thresholds (More lenient for conversational)
CHAT_CONF_THRESHOLD=0.15

# Early Termination (More aggressive for speed)
CHAT_EARLY_TERMINATION_THRESHOLD=0.80

# Database Optimizations
CHAT_IVF_PROBES=8
CHAT_HNSW_EF_SEARCH=30

# Metadata Filtering (Balanced for conversational)
CHAT_USE_METADATA_FILTERING=true
CHAT_METADATA_MIN_TOPICS=2

# Performance Monitoring
PERFORMANCE_MONITORING_ENABLED=true
